{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import redis\n",
    "from time import gmtime, strftime\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "client = MongoClient()\n",
    "R = redis.StrictRedis(host='127.0.0.1', port=6379, db=0)\n",
    "R.flushdb()\n",
    "for k in R.scan_iter(\"stud:12:*\"):\n",
    "    R.delete(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Creating DB \n",
    "db = client['stud12']\n",
    "collection = db['Work']\n",
    "collection.drop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##add company function\n",
    "#In this question, we'll look for the company name in the cache due to efficiency considerations.\n",
    "#If found, it means the collection includes this value; otherwise, we'll add it  \n",
    "#Redis can check the existence of keys only, not value!!\n",
    "\n",
    "def add_company(company):\n",
    "        if type(company) is dict:\n",
    "            key='stud12:companies:' + company['company_name']                \n",
    "            if R.exists(key):\n",
    "                print('Company name exists in the collection')\n",
    "            else:\n",
    "                R.set(key,company['company_name'])\n",
    "                collection.insert_one(company)\n",
    "                print('Company name was added to the collection')\n",
    "        else:\n",
    "            print('You should insert a dictionary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#the job ID should be unique for a given company  and automatically generated when a new job is added to the company     \n",
    "def add_job(job,company):\n",
    "    #check if company exists - Redis\n",
    "    #check if position exists - Redis\n",
    "        #if not add position s\n",
    "        #count number of positions\n",
    "    #update job id\n",
    "    #update status\n",
    "    key='stud12:companies:' + company\n",
    "    key_position='stud12:'+company+':' +job['job_title']\n",
    "    key_id='stud12:companies:id:' + company\n",
    "    if R.exists(key): #if the company exsist in the collection we can continue\n",
    "        if R.exists(key_position): #does the position exist?\n",
    "            print('the following position:{} has been inserted already into the database'.format(job['job_title']))\n",
    "        else:\n",
    "            if not R.exists(key_id): #initialization of job id  \n",
    "                R.set(key_id,0) \n",
    "            job_id=R.incr(key_id) #incrementation of job id\n",
    "            R.set(key_id,job_id) \n",
    "            R.set(key_position,job_id)\n",
    "            key_position_id='stud12:'+company+':' +str(job_id)\n",
    "            R.set(key_position_id, job_id)\n",
    "            key_status='stud12:status:' + company +':' + str(job_id)\n",
    "            R.set(key_status, job['status'])\n",
    "            job['JobId'] = R.get(key_id) #get job id value from Redis update in mongoDB\n",
    "            collection.update_one({'company_name':company }, {'$push': {'positions': job}},upsert=True) \n",
    "            print('All set, the job was added')\n",
    "    else:\n",
    "        print('Company: {} does not exsist in the collection'.format(company))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-153-7df0bfda0a31>, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-153-7df0bfda0a31>\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def add_application(candidate, job_id,company_name):\n",
    "#Check company is in collection\n",
    "#check position is in collection in company\n",
    "#check if position is open \n",
    "#check if candidate applied with unique e-mail\n",
    "#all validations are through redis\n",
    "#if not appliued add candidate\n",
    "    # add timestamp to candidate application \n",
    "    key='stud12:companies:' + company_name \n",
    "    key_position_id='stud12:'+company_name+':' +str(job_id)\n",
    "    key_status='stud12:status:' + company_name +':' + str(job_id)\n",
    "    key_email='stud12:'+company_name +':' + str(job_id)+':'+ candidate['email']\n",
    "    if R.exists(key): #if the company exsist in the collection we can continue\n",
    "        if R.exists(key_position_id): #if position exists continue\n",
    "            if R.get(key_status)=='open': # if position is open continue, \n",
    "                if not R.exists(key_email): #if e-mail does not exist, candidate will apply \n",
    "                    R.set(key_email, job_id)      \n",
    "                    candidate['ApplicationDate'] = datetime.now()           \n",
    "                    collection.update_one({'company_name':company_name,\"positions.JobId\":job_id}, {'$push': {'positions.$.Applications': candidate}}) \n",
    "                    print('Candidate added to applicants list')\n",
    "            \n",
    "                else: \n",
    "                    print('candidate already applied to job')\n",
    "            else: \n",
    "                print('Position: {} is closed'.format(job_id))\n",
    "        else: \n",
    "            print( 'Position: {} does not exist'.format(job_id)    \n",
    "    else: \n",
    "        print('Company: {} does not exsist in the collection'.format(company_name))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_job_status(company_name, job_id, new_status):\n",
    "    #Check company is in collection\n",
    "    #check position is in collection in company\n",
    "    #check position's status\n",
    "        #change status\\leave as is\n",
    "    key='stud12:companies:' + company_name \n",
    "    key_position_id='stud12:'+company_name+':' +str(job_id)\n",
    "    key_status='stud12:status:' + company_name +':' + str(job_id)    \n",
    "    if R.exists(key): #if the company exsist in the collection we can continue\n",
    "        if R.exists(key_position_id): #if position exists continue\n",
    "            if R.get(key_status)!=new_status: # check if status needs to be changed\n",
    "                    R.set(key_status,new_status) # update in Redis\n",
    "                    MyQuery= {\"company_name\":company_name, \"positions.JobId\":job_id}\n",
    "                    #location=\"positions.{}\".format(str(job_id))\n",
    "                    MyValue= {\"$set\":{\"positions.$.status\":new_status,\"positions.$.modifiedDate\":strftime(\"%d-%m-%Y\", gmtime())}}\n",
    "                    collection.update_one(MyQuery,MyValue)\n",
    "                    print('status is changed')\n",
    "            else: \n",
    "                print('status is already {}'.format(new_status))\n",
    "        else:  \n",
    "            print( 'Position: {} does not exist'.format(job_id)) \n",
    "    else:\n",
    "        print('Company: {} does not exsist in the collection'.format(company_name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_number_of_jobs(location,job_title):\n",
    "    #aggregate function according to:\n",
    "    #position=open\n",
    "    #location\n",
    "    #job title\n",
    "    \n",
    "    agg_result= list(collection.aggregate([{\"$unwind\":'$positions'},{\"$match\":{'positions.job_title':job_title,'positions.status':'open','positions.location':location}},{'$group':{'_id':{},\"num_jobs\": {\"$sum\": 1}}}]))\n",
    "    df=pd.DataFrame(agg_result)\n",
    "    if df.empty:\n",
    "        print('no open positions for location: {} and job: {}'.format(location,job_title))\n",
    "    else:\n",
    "        print df \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_candidates(company_name,job_id):\n",
    "    aggregation_function = [{\"$unwind\":'$positions'},\n",
    "                         {\"$match\":{\"company_name\":company_name,\"positions.JobId\":job_id}},{\"$unwind\":'$positions.Applications'},\n",
    "                        {\"$project\":{\"email\":\"$positions.Applications.email\",\n",
    "                                     \"skills\":\"$positions.Applications.skills\",\n",
    "                                     \"job_requirments\":'$positions.requirements','_id':0}},\n",
    "                                     {'$project':{'commonToBoth': \n",
    "                                      {\"$size\":[{ '$setIntersection': [ \"$job_requirments\", '$skills' ]}]}\n",
    "                                                  ,'_id':'$email'}},\n",
    "                        {\"$sort\":{\"commonToBoth\":1}}]\n",
    "    pprint.pprint(list(collection.aggregate(aggregation_function)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_jobs_by_date():\n",
    "    if not list(collection.find({}))==[]:\n",
    "        \n",
    "    \n",
    "        ##our assumtion in this implemtation: 1. new position inserted into the collection is open\n",
    "         # changing status can be only once- from open to close only \n",
    "\n",
    "\n",
    "        # 1.Handeling open positions\n",
    "        # Assuming publish date as an open position - counting the number of positions published per date     \n",
    "        aggregation_function = collection.aggregate([\n",
    "        {\"$unwind\":\"$positions\"},\n",
    "        {\"$group\": {\"_id\": \"$positions.publish_date\", \"open_positions\": {\"$sum\": 1}}}])\n",
    "        open_jobs=pd.DataFrame(list(aggregation_function))\n",
    "\n",
    "\n",
    "        #2.Handeling closed positions\n",
    "        #Assuming modified date as a close position(the change can be from open to close only)\n",
    "\n",
    "        aggregation_function_close = collection.aggregate([\n",
    "        {\"$unwind\":\"$positions\"},\n",
    "        {\"$match\":{\"positions.status\":\"close\"}},\n",
    "        {\"$group\": {\"_id\": \"$positions.modifiedDate\", \"close_positions\": {\"$sum\": 1}}}])\n",
    "\n",
    "        ##Inserting the data into table \n",
    "        closed_jobs=pd.DataFrame(list(aggregation_function_close))\n",
    "\n",
    "\n",
    "        ##merging tables -open and close jobs\n",
    "        try:\n",
    "            merged_df = pd.merge(open_jobs, closed_jobs, how=\"outer\", on=\"_id\")\n",
    "        except: \n",
    "            merged_df=closed_jobs\n",
    "            merged_df['open_positions']=pd.Series([0 for x in range(len(merged_df.index))])\n",
    "\n",
    "        ##Sorting by date\n",
    "\n",
    "        merged_df = merged_df.sort_values(by=\"_id\")\n",
    "\n",
    "        ##calculations\n",
    "        merged_df[\"cumulative_open\"]=merged_df['open_positions'].cumsum(skipna=True)\n",
    "        merged_df[\"cumulative_close\"]=merged_df['close_positions'].cumsum(skipna=True)\n",
    "        merged_df=merged_df.replace(np.nan, 0)\n",
    "        merged_df['final_open']=merged_df[\"cumulative_open\"]-merged_df[\"cumulative_close\"]\n",
    "\n",
    "        ##Final data frames with the relevant columns \n",
    "        final_df=merged_df[[\"_id\",\"final_open\",\"cumulative_close\"]]\n",
    "        final=final_df.rename(columns={'_id': \"Date\", \"final_open\": \"number_of_open_jobs\",\"cumulative_close\": \"number_of_close_jobs\"})\n",
    "        #final=pd.to_datetime(final['Date'])\n",
    "\n",
    "        ##Limiting results to 2020 \n",
    "        start_date = datetime.strptime(\"01-01-2020\",'%d-%m-%Y') \n",
    "        end_date = datetime.strptime(\"31-12-2020\",'%d-%m-%Y') \n",
    "\n",
    "        final['Date'] = pd.to_datetime(final['Date'])  \n",
    "\n",
    "        filtered_dates = final[(final['Date']>= start_date) & (final['Date']<=  end_date)]\n",
    "\n",
    "\n",
    "        print filtered_dates \n",
    "    else:\n",
    "        print ('collection is empty')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_candidates_by_job():\n",
    "\n",
    "##Defining the duration of time of the retrieved results \n",
    "    N_DAYS_AGO = 30\n",
    "    now = datetime.now() # current date and time\n",
    "    n_days_ago = now - timedelta(days=N_DAYS_AGO)\n",
    "   \n",
    "\n",
    "    ##Unwinding candidates, filtering the data from the last 30 days and counting the numbers of applications\n",
    "    pipeline = [\n",
    "        {\"$unwind\": \"$positions\"},{\"$match\":{\n",
    "       \"positions.Applications.ApplicationDate\":{\"$gte\":n_days_ago}}},\n",
    "        {\"$group\": {'_id':{\n",
    "            \"ID\": \"$positions.JobId\",\"company\":\"$company_name\",\n",
    "            \"candidates\": \"$positions.Applications.email\"}, \"candidats\": {\"$sum\":1 }}}\n",
    "           \n",
    "    ]\n",
    "\n",
    "    df1=pd.DataFrame(list(collection.aggregate(pipeline)))\n",
    "    \n",
    "    ##creating new data frame for storing the relevant data\n",
    "    col = ['job','candidates']\n",
    "    df = pd.DataFrame(columns=col)\n",
    "\n",
    "    for index, row in df1.iterrows():\n",
    "        df.loc[index,'job']= row['_id']['ID']+ '_' +row['_id']['company']\n",
    "        df.loc[index,'candidates']=len(row['_id']['candidates'])\n",
    "    \n",
    "    \n",
    "    print df\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "update_job_status('TAU','2','close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## run to see database model(You can find it in the attached word file as well)\n",
    "list(collection.find({}))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##recovery the rellevant keys we stored in redis:\n",
    "def recovery():\n",
    "    for doc in collection.find():\n",
    "        company_name=doc['company_name']\n",
    "        key = 'stud12:companies:' + company_name##key\n",
    "        R.set(key,company_name)\n",
    "\n",
    "        # recovery number of jobs per company \n",
    "        key_id='stud12:companies:id' + company_name\n",
    "        if 'positions' in doc:\n",
    "            value = len(doc['positions'])\n",
    "            R.set(key_id,value)\n",
    "         \n",
    "        else:\n",
    "            R.set(key_id,0)\n",
    "\n",
    "        ## Recovery key position id,position name ans status\n",
    "        if 'positions' in doc:\n",
    "            for i in doc['positions']:\n",
    "                print i\n",
    "                key_position='stud12:'+company_name+':' +i['job_title']\n",
    "                key_position_id='stud12:'+company_name+':' +str(i['JobId'])\n",
    "                key_status='stud12:companies:status' + company_name + str(i['JobId'])\n",
    "               \n",
    "                ##Recovery email adress\n",
    "                for email in i['Applications']:\n",
    "                    email_address=email['email']\n",
    "\n",
    "                    key_email='stud12:'+company_name +':' + str(i['JobId'])+':'+ email_address\n",
    "                    R.set(key_email,i['JobId'])\n",
    "                \n",
    "\n",
    "                R.set(key_position,i['JobId'])\n",
    "                R.set(key_position_id,i['JobId'])\n",
    "                R.set(key_status,i['status'])\n",
    "              \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def execution():\n",
    "#operation 1\n",
    "    add_company({'company_name':'TAU','company_description':'University'})\n",
    "#operation 2\n",
    "    add_job({'job_title':'bi developer', 'location': 'Tel Aviv',\n",
    "'requirements':['python','big data','mongodb'],\n",
    "'status':'open','publish_date':'01-02-2020'},'TAU')\n",
    "#operation 3\n",
    "    add_application({'candidate_name':'laura', 'email':'laura@gmail.com',\n",
    "'linkedin':'https://www.linkedin.com/in/laura/', 'skills': ['python','sql'],\n",
    "'application_date':'01-02-2019 15:00:00'}, '1','TAU')\n",
    "#operation 4\n",
    "    update_job_status('TAU','1','close')\n",
    "#operation 5\n",
    "    show_number_of_jobs('Tel Aviv','bi developer')\n",
    "#operation 6\n",
    "    show_candidates('TAU','1')\n",
    "\n",
    "#report1\n",
    "    count_jobs_by_date()\n",
    "\n",
    "#report2\n",
    "    count_candidates_by_job()\n",
    "    if not R.ping():\n",
    "        recovery()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company name exists in the collection\n",
      "the following position:bi developer has been inserted already into the database\n",
      "Position is closed\n",
      "status is already close\n",
      "no open positions for location: Tel Aviv and job: bi developer\n",
      "[{u'_id': u'laura@gmail.com', u'commonToBoth': 1}]\n",
      "        Date  number_of_open_jobs  number_of_close_jobs\n",
      "0 2020-01-02                  1.0                   0.0\n",
      "     job candidates\n",
      "0  1_TAU          1\n"
     ]
    }
   ],
   "source": [
    "execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
